# main.py
import feedparser
import requests
from datetime import datetime, timedelta
import sys

# âœ… ç›´æ¥å¯«å…¥ token å’Œ database IDï¼ˆâš ï¸ åƒ…é™æ¸¬è©¦ï¼‰
NOTION_TOKEN = "ntn_Eq42642401088NbxGGoTVevHnW4eOJ94SCEkrBwOtjy9gQ"  # è«‹æ›¿æ›ç‚ºä½ çš„ token
NOTION_DATABASE_ID = "2450196ab6ca8037b2e4c4f6f1537649"  # è«‹æ›¿æ›ç‚ºä½ çš„è³‡æ–™åº« ID

HEADERS = {
    "Authorization": f"Bearer {NOTION_TOKEN}",
    "Content-Type": "application/json",
    "Notion-Version": "2022-06-28"
}

# è¨­å®šè¦è®€å–çš„ RSS æ¸…å–®ï¼ˆè·ä½å°æ‡‰åˆ†é¡ï¼‰
RSS_FEEDS = [
    {"è·ä½": "CEO", "åˆ†é¡": "å…¨çƒè²¡ç¶“", "url": "https://www.bloomberg.com/feed"},
    {"è·ä½": "COO", "åˆ†é¡": "ä¾›æ‡‰éˆå‹•æ…‹", "url": "https://www.supplychaindive.com/rss/"},
    {"è·ä½": "CFO", "åˆ†é¡": "è²¡å‹™èˆ‡æœƒè¨ˆç­–ç•¥", "url": "https://www.cfodive.com/rss/"},
    {"è·ä½": "CTO", "åˆ†é¡": "æŠ€è¡“ç­–ç•¥", "url": "https://feed.infoq.com/"},
    {"è·ä½": "CIO", "åˆ†é¡": "è³‡å®‰æ²»ç†", "url": "https://www.cio.com/index.rss"},
]

now = datetime.utcnow()
seven_days_ago = now - timedelta(days=7)

# æª¢æŸ¥ Notion æ˜¯å¦å·²ç¶“æœ‰è©²æ¢ç›®ï¼ˆç”¨ URL ç•¶å”¯ä¸€éµï¼‰
def is_duplicate(url):
    try:
        search_url = f"https://api.notion.com/v1/databases/{NOTION_DATABASE_ID}/query"
        payload = {
            "filter": {
                "property": "é€£çµ",
                "url": {"equals": url}
            }
        }
        response = requests.post(search_url, headers=HEADERS, json=payload)
        response.raise_for_status()
        data = response.json()
        return len(data.get("results", [])) > 0
    except Exception as e:
        print(f"âš ï¸ æŸ¥é‡å¤±æ•—: {e}")
        return False

# å°‡è³‡æ–™å¯«å…¥ Notion
def create_page(item, è·ä½, åˆ†é¡):
    try:
    test_payload = {
        "parent": {"database_id": NOTION_DATABASE_ID},
        "properties": {
            "æ¨™é¡Œ": {"title": [{"text": {"content": "âœ… æ¸¬è©¦ï¼šNotion å¯«å…¥æ¸¬è©¦"}}]},
            "æ‘˜è¦": {"rich_text": [{"text": {"content": f"åŸ·è¡Œæ–¼ {now.strftime('%Y-%m-%d %H:%M:%S')} UTC"}}]},
            "åˆ†é¡": {"select": {"name": "æŠ€è¡“ç­–ç•¥"}},
            "é©åˆä¸»ç®¡": {"select": {"name": "CTO"}},
            "é€£çµ": {"url": "https://example.com/test-log"},
            "ç™»éŒ„æ—¥æœŸ": {"date": {"start": now.strftime("%Y-%m-%d")}},
            "äº‹ä»¶ç™¼ç”Ÿæ—¥æœŸ": {"date": {"start": now.strftime("%Y-%m-%d")}},
            "è©²æ³¨æ„å“ªäº›ï¼Ÿ": {"rich_text": [{"text": {"content": "åƒ…ä¾›æ¸¬è©¦ç”¨é€”"}}]}
        }
    }
    test_res = requests.post("https://api.notion.com/v1/pages", headers=HEADERS, json=test_payload)
    test_res.raise_for_status()
    print("ğŸ“ æˆåŠŸå¯«å…¥æ¸¬è©¦ log è‡³ Notion")
except Exception as e:
    print(f"ğŸš« æ¸¬è©¦ log å¯«å…¥å¤±æ•—ï¼š{e}")

# åŸ·è¡Œä¸»é‚è¼¯
for feed in RSS_FEEDS:
    print(f"ğŸ“¡ è™•ç†ä¾†æºï¼š{feed['url']}")
    d = feedparser.parse(feed["url"])
    for entry in d.entries:
        if hasattr(entry, "published_parsed"):
            pub_dt = datetime(*entry.published_parsed[:6])
            if pub_dt >= seven_days_ago:
                if not is_duplicate(entry.link):
                    create_page(entry, feed["è·ä½"], feed["åˆ†é¡"])
                else:
                    print("ğŸ” è·³éé‡è¤‡ï¼š", entry.title)
